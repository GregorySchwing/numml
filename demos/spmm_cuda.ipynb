{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a349ef13-8c23-40c6-8d69-d7d93104a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing CUDA spgemm implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ca425-7260-49a1-89eb-7ba28b59ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import numml.sparse as sp\n",
    "import time\n",
    "sp_cpp = sp.numml_torch_cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b586d-7aaf-4e83-a16b-81f22f477f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large(r) poisson problem\n",
    "# We'll compute the product A @ (-A)\n",
    "\n",
    "N = 1024\n",
    "A = sp.eye(N) * 2 - sp.eye(N, k=-1) - sp.eye(N, k=1)\n",
    "B = (-A).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c6639-910d-419a-b3a4-de85dbb0a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move both over to GPU\n",
    "A_c = A.to('cuda:0')\n",
    "B_c = B.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88bc160-50a0-4de1-a6ac-c61259c72ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure both implementations are identical\n",
    "torch.allclose((A_c@B_c).cpu().data, (A@B).data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5324d704-d13e-4f63-8ed8-82cfbf7bb6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward timing test\n",
    "\n",
    "N_it = 300\n",
    "print(f'Performing {N_it} sparse matmat (forward pass)')\n",
    "\n",
    "t_start = time.time()\n",
    "for i in range(N_it):\n",
    "    C = A@B\n",
    "t_cpu = time.time() - t_start\n",
    "print('CPU time:', t_cpu)\n",
    "\n",
    "t_start = time.time()\n",
    "for i in range(N_it):\n",
    "    C_c = A_c@B_c\n",
    "torch.cuda.synchronize()\n",
    "t_cuda = time.time() - t_start\n",
    "print('GPU time:', t_cuda)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff93fa6-16a9-45a2-b413-3545b0bed425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test that our GPU grad matches the CPU grad\n",
    "\n",
    "A_c.requires_grad = True\n",
    "B_c.requires_grad = True\n",
    "C_c = A_c @ B_c\n",
    "C_c.sum().backward()\n",
    "\n",
    "A.requires_grad = True\n",
    "B.requires_grad = True\n",
    "C = A@B\n",
    "C.sum().backward()\n",
    "\n",
    "print(torch.allclose(A_c.grad.data.cpu(), A.grad.data))\n",
    "print(torch.allclose(B_c.grad.data.cpu(), B.grad.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c722477-6d28-41d1-a19b-747ee86c2cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward timing test\n",
    "\n",
    "N_it = 100\n",
    "print(f'Performing {N_it} sparse matmat (backward pass)')\n",
    "\n",
    "t_start = time.time()\n",
    "for i in range(N_it):\n",
    "    C = A@B\n",
    "    C.sum().backward()\n",
    "t_cpu = time.time() - t_start\n",
    "print('CPU time:', t_cpu)\n",
    "\n",
    "t_start = time.time()\n",
    "for i in range(N_it):\n",
    "    C_c = A_c@B_c\n",
    "    C_c.sum().backward()\n",
    "torch.cuda.synchronize()\n",
    "t_cuda = time.time() - t_start\n",
    "print('GPU time:', t_cuda)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f84fc17-d767-4ed1-8893-1eaf06ade829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
